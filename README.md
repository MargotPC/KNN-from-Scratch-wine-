# ğŸ§  KNN desde cero y comparaciÃ³n con KStar (Weka)

ImplementaciÃ³n del algoritmo **k-Nearest Neighbors (KNN)** completamente **desde cero en Python**, aplicada al conjunto de datos clÃ¡sico **Wine**.  
El proyecto incluye la evaluaciÃ³n del modelo mediante **validaciÃ³n cruzada (5-fold)** y **Leave-One-Out (LOOCV)**, ademÃ¡s de la comparaciÃ³n con el clasificador **KNN de scikit-learn** y el algoritmo **KStar** de **Weka**.
---

## âš™ï¸ CaracterÃ­sticas principales

- ImplementaciÃ³n manual del algoritmo **KNN**, sin uso de librerÃ­as de machine learning.  
- MÃ©tricas de distancia disponibles:
  - Euclidiana  
  - Manhattan  
  - Coseno  
- SelecciÃ³n del parÃ¡metro Ã³ptimo \( k \) mediante **validaciÃ³n cruzada 5-fold**.  
- EvaluaciÃ³n de desempeÃ±o mediante:
  - Accuracy  
  - Matriz de confusiÃ³n  
  - ValidaciÃ³n **LOOCV (Leave-One-Out)**  
- ComparaciÃ³n con:
  - `KNeighborsClassifier` de **scikit-learn**  
  - **KStar** (mÃ©trica basada en entropÃ­a) de **Weka**

---

## ğŸ“Š Resultados principales

| Distancia  | k Ã³ptimo | Accuracy (CV) | Accuracy (LOOCV) | Accuracy sklearn (CV) |
|-------------|-----------|----------------|-------------------|------------------------|
| Euclidiana  | 15 | 0.9776 | 0.9775 | 0.9775 |
| Manhattan   | 17 | 0.9778 | 0.9775 | 0.9719 |
| Coseno      | 3  | 0.9722 | 0.9663 | 0.9551 |

**KStar (Weka, B=20):** Accuracy = **73.0 %**

---

## ğŸš€ EjecuciÃ³n

Para ejecutar el modelo, abre el notebook:
```bash
Script_KNN_MargotPaco.ipynb
```

### ğŸ”¹ OpciÃ³n 1 â€” Desde Jupyter Notebook o JupyterLab
1. Abre tu entorno Jupyter (`jupyter notebook` o `jupyter lab` en la terminal).  
2. Navega hasta el archivo `Script_KNN_MargotPaco.ipynb`.  
3. Ejecuta las celdas en orden (menÃº **Kernel â†’ Restart & Run All**).

### ğŸ”¹ OpciÃ³n 2 â€” Desde VS Code o Google Colab
- En **VS Code**, instala la extensiÃ³n *Jupyter* y abre el `.ipynb` directamente.  
- En **Google Colab**, sube el notebook y ejecuta las celdas online (solo necesitas `numpy` y `pandas`).

### ğŸ”§ ParÃ¡metros configurables
Dentro del notebook puedes modificar los valores de **k** y **distancia**:
```python
k = 15
dist_name = "euclidean"  # opciones: "manhattan", "cosine"
```

---

## ğŸ§¾ Informe

El proyecto incluye un informe acadÃ©mico en formato PDF con los resultados, anÃ¡lisis y comparaciones:
ğŸ“„ `Informe_KNN_MargotPaco.pdf`

---

## ğŸ§© Conclusiones

- La implementaciÃ³n manual del algoritmo KNN reproduce correctamente los resultados del modelo de **scikit-learn**, validando su funcionamiento.  
- Las mÃ©tricas **Euclidiana** y **Manhattan** ofrecen el mejor rendimiento (â‰ˆ97.7 % de exactitud).  
- La distancia **del Coseno** presenta una ligera disminuciÃ³n en precisiÃ³n debido a su dependencia angular.  
- El clasificador **KStar** de **Weka**, basado en entropÃ­a, obtiene un rendimiento menor (â‰ˆ73 %) al aplicarse sobre un conjunto puramente numÃ©rico y bien separado como *Wine*.

---

## ğŸ§ª Requisitos

- Python â‰¥ 3.8  
- NumPy â‰¥ 1.24  
- Pandas (solo para manejo de datos CSV)  
- Weka (para la comparaciÃ³n con KStar)
---

## ğŸ‘©â€ğŸ’» Autora

**Margot P.C.**  
ğŸ“˜ [Repositorio en GitHub](https://github.com/MargotPC/KNN-from-Scratch-wine-)
